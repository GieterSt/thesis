#!/usr/bin/env python3
"""
DATA LOADING AND GROUND TRUTH UTILITIES
Handles loading and processing of test data and ground truth comparisons
"""
import json
import os
import numpy as np
from pathlib import Path

# Get the script's directory to build robust paths
SCRIPT_DIR = Path(__file__).parent.resolve()
PROJECT_ROOT = SCRIPT_DIR.parent

# Ground truth data paths
GROUND_TRUTH_PATHS = {
    'json': PROJECT_ROOT / 'data/input-output pairs json/test_ground_truth.json',
    'excel': PROJECT_ROOT / 'data/ground_truth/test_set_ground_truth_complete.xlsx'
}

def load_ground_truth():
    """Load optimal allocations generated by greedy algorithm for comparison"""
    print("\n" + "="*80)
    print("📊 STEP 1: LOADING GROUND TRUTH DATA")
    print("="*80)
    
    try:
        if os.path.exists(GROUND_TRUTH_PATHS['json']):
            print(f"✅ Loading ground truth from: {GROUND_TRUTH_PATHS['json']}")
            with open(GROUND_TRUTH_PATHS['json'], 'r', encoding='utf-8') as f:
                ground_truth = json.load(f)
            
            print(f"📈 Loaded {len(ground_truth)} ground truth scenarios")
            print("🎯 Ground truth contains optimal allocations from greedy algorithm")
            
            # Process ground truth into lookup format
            gt_lookup = {}
            for i, scenario in enumerate(ground_truth):
                date = scenario['input']['date']
                gt_lookup[i] = {
                    'date': date,
                    'daily_total_required': scenario['input']['daily_total_ppfd_requirement'],
                    'optimal_allocations': {},
                    'scenario_complexity': calculate_scenario_complexity(scenario)
                }
                
                # Extract optimal hourly allocations
                for hour_result in scenario['output']['hourly_results']:
                    hour = hour_result['hour']
                    ppfd = hour_result['ppfd_allocated']
                    gt_lookup[i]['optimal_allocations'][f'hour_{hour}'] = ppfd
            
            return gt_lookup
            
    except Exception as e:
        print(f"❌ Error loading ground truth: {e}")
        return None

def calculate_scenario_complexity(scenario):
    """Calculate complexity score for scenario"""
    ppfd_requirement = scenario['input']['daily_total_ppfd_requirement']
    date = scenario['input']['date']
    
    # Parse date to determine season
    month = int(date.split('-')[1])
    if month in [12, 1, 2]:
        season = 'Winter'
        complexity_base = 3.0
    elif month in [3, 4, 5]:
        season = 'Spring'
        complexity_base = 2.0
    elif month in [6, 7, 8]:
        season = 'Summer'
        complexity_base = 1.0
    else:
        season = 'Autumn'
        complexity_base = 2.0
    
    # PPFD requirement complexity
    ppfd_complexity = min(ppfd_requirement / 2000, 3.0)  # Scale 0-3
    
    total_complexity = complexity_base + ppfd_complexity
    
    return {
        'season': season,
        'ppfd_requirement': ppfd_requirement,
        'complexity_score': total_complexity,
        'complexity_category': 'High' if total_complexity > 4.0 else 'Medium' if total_complexity > 2.5 else 'Low'
    }

def calculate_ground_truth_metrics(model_allocations, ground_truth, test_case_index):
    """Compare model allocations against optimal greedy algorithm solution"""
    if ground_truth is None or test_case_index not in ground_truth:
        return None
    
    gt_scenario = ground_truth[test_case_index]
    optimal_allocations = gt_scenario['optimal_allocations']
    
    # Calculate comparison metrics
    hourly_matches = []
    absolute_errors = []
    relative_errors = []
    
    total_model_ppfd = 0
    total_optimal_ppfd = sum(optimal_allocations.values())
    
    for hour_key in optimal_allocations:
        optimal_value = optimal_allocations[hour_key]
        model_value = model_allocations.get(hour_key, 0)
        
        total_model_ppfd += model_value
        
        # Exact match check (within small tolerance for floating point)
        is_exact_match = abs(model_value - optimal_value) < 0.01
        hourly_matches.append(is_exact_match)
        
        # Calculate errors
        abs_error = abs(model_value - optimal_value)
        absolute_errors.append(abs_error)
        
        if optimal_value > 0:
            rel_error = abs_error / optimal_value * 100
            relative_errors.append(rel_error)
    
    # Daily total comparison
    daily_abs_error = abs(total_model_ppfd - total_optimal_ppfd)
    daily_rel_error = (daily_abs_error / total_optimal_ppfd * 100) if total_optimal_ppfd > 0 else 0
    
    return {
        'exact_24h_match': sum(hourly_matches) == 24,
        'hourly_matches': sum(hourly_matches),
        'hourly_match_rate': sum(hourly_matches) / 24 * 100,
        'mean_absolute_error': np.mean(absolute_errors),
        'daily_absolute_error': daily_abs_error,
        'daily_relative_error': daily_rel_error,
        'total_model_ppfd': total_model_ppfd,
        'total_optimal_ppfd': total_optimal_ppfd,
        'scenario_complexity': gt_scenario['scenario_complexity']
    }

def analyze_seasonal_performance(ground_truth_comparisons):
    """Analyze performance by season"""
    seasonal_data = {'Spring': [], 'Summer': [], 'Autumn': [], 'Winter': []}
    
    for comparison in ground_truth_comparisons:
        if comparison:
            season = comparison['scenario_complexity']['season']
            seasonal_data[season].append(comparison['hourly_match_rate'])
    
    seasonal_stats = {}
    for season, rates in seasonal_data.items():
        if rates:
            seasonal_stats[season] = {
                'mean_rate': np.mean(rates),
                'std_rate': np.std(rates),
                'count': len(rates)
            }
        else:
            seasonal_stats[season] = {
                'mean_rate': 0,
                'std_rate': 0,
                'count': 0
            }
    
    return seasonal_stats 