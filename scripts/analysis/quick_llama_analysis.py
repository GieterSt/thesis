#!/usr/bin/env python3
"""
Quick analysis of Llama 3.3 70B results
"""
import json
import pandas as pd
import re
import numpy as np
from datetime import datetime

def analyze_llama_results():
    # Load the completed Llama results
    MODEL_RESULTS_FILE = 'results/model_outputs/meta-llama_llama-3.3-70b-instruct_free_results_v1_prompt.json'
    
    print('üéâ LLAMA 3.3 70B ANALYSIS RESULTS')
    print('=' * 50)
    
    try:
        with open(MODEL_RESULTS_FILE, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except FileNotFoundError:
        print(f"‚ùå Error: Results file not found: {MODEL_RESULTS_FILE}")
        return
    except json.JSONDecodeError:
        print(f"‚ùå Error: Could not decode JSON from {MODEL_RESULTS_FILE}")
        return

    total_items = len(results)
    valid_json_count = 0
    successful_responses = 0
    total_api_time = 0
    allocation_responses = 0
    
    # Sample responses for quality check
    sample_responses = []

    for item in results:
        response = item.get('openrouter_model_response')
        api_duration = item.get('api_call_duration_seconds', 0)
        total_api_time += api_duration
        
        if response is not None:
            successful_responses += 1
            if isinstance(response, dict):
                valid_json_count += 1
                
                # Check if it contains allocation data
                if 'allocation_PPFD_per_hour' in response or 'allocation PPFD_per_hour' in response:
                    allocation_responses += 1
                
                # Collect sample for inspection
                if len(sample_responses) < 3:
                    sample_responses.append(response)

    # Calculate metrics
    success_rate = (successful_responses / total_items) * 100 if total_items > 0 else 0
    json_rate = (valid_json_count / total_items) * 100 if total_items > 0 else 0
    allocation_rate = (allocation_responses / total_items) * 100 if total_items > 0 else 0
    avg_response_time = total_api_time / successful_responses if successful_responses > 0 else 0

    print(f'üìä Performance Metrics:')
    print(f'   Total test cases: {total_items}')
    print(f'   Successful API calls: {successful_responses}')
    print(f'   Success rate: {success_rate:.1f}%')
    print(f'   Valid JSON responses: {valid_json_count}')
    print(f'   JSON success rate: {json_rate:.1f}%')
    print(f'   Responses with allocations: {allocation_responses}')
    print(f'   Allocation success rate: {allocation_rate:.1f}%')
    print(f'   Total API time: {total_api_time:.1f}s ({total_api_time/60:.1f} minutes)')
    print(f'   Average response time: {avg_response_time:.1f}s')
    
    print(f'\nüí∞ Cost Analysis:')
    print(f'   Model: Llama 3.3 70B Instruct')
    print(f'   Cost: FREE! üéâ')
    print(f'   Total estimated tokens: ~{successful_responses * 2000:,}')
    print(f'   Estimated value if paid: $0 (completely free)')
    
    print(f'\nüìö Thesis Analysis Readiness:')
    if valid_json_count >= 40:
        print(f'   üéâ EXCELLENT! {valid_json_count} valid responses - perfect for thesis analysis!')
    elif valid_json_count >= 30:
        print(f'   ‚úÖ VERY GOOD! {valid_json_count} valid responses - excellent for thesis analysis')
    elif valid_json_count >= 20:
        print(f'   ‚úÖ GOOD! {valid_json_count} valid responses - sufficient for thesis analysis')
    else:
        print(f'   ‚ö†Ô∏è LIMITED! {valid_json_count} valid responses - may need improvement')
    
    print(f'\nüìù Sample Response Structure:')
    if sample_responses:
        sample = sample_responses[0]
        print(f'   Keys in response: {list(sample.keys())[:5]}...')
        if 'allocation_PPFD_per_hour' in sample:
            alloc = sample['allocation_PPFD_per_hour']
            print(f'   Allocation keys: {list(alloc.keys())[:5]}...')
            print(f'   Sample hour_0 value: {alloc.get("hour_0", "N/A")}')
    
    print(f'\nüîÑ Comparison with Other Models:')
    print(f'   Llama 3.3 70B: {valid_json_count}/72 valid JSON ({json_rate:.1f}%)')
    print(f'   DeepSeek R1 Distill: Running... (target: 30+ responses)')
    print(f'   Mistral 7B Improved: Running... (target: 15+ responses)')
    print(f'   DeepSeek R1 0528: Running... (very slow but high quality)')
    
    print(f'\n‚úÖ CONCLUSION: Llama 3.3 70B provides excellent baseline results!')
    print('=' * 50)

if __name__ == "__main__":
    analyze_llama_results() 